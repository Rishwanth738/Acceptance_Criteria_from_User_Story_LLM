{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":12130072,"sourceType":"datasetVersion","datasetId":7638522}],"dockerImageVersionId":31041,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install -q transformers peft accelerate bitsandbytes\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-11T11:18:58.928781Z","iopub.execute_input":"2025-06-11T11:18:58.929045Z","iopub.status.idle":"2025-06-11T11:20:18.480778Z","shell.execute_reply.started":"2025-06-11T11:18:58.929021Z","shell.execute_reply":"2025-06-11T11:20:18.479778Z"}},"outputs":[{"name":"stdout","text":"\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.0/67.0 MB\u001b[0m \u001b[31m24.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m30.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m13.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m81.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25h","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"extract_dir = \"/kaggle/input/llm-mistral\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-11T11:21:34.345845Z","iopub.execute_input":"2025-06-11T11:21:34.346557Z","iopub.status.idle":"2025-06-11T11:21:34.349728Z","shell.execute_reply.started":"2025-06-11T11:21:34.346534Z","shell.execute_reply":"2025-06-11T11:21:34.349198Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"from huggingface_hub import notebook_login\n\nnotebook_login()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-11T11:21:36.107456Z","iopub.execute_input":"2025-06-11T11:21:36.108069Z","iopub.status.idle":"2025-06-11T11:21:36.128299Z","shell.execute_reply.started":"2025-06-11T11:21:36.108046Z","shell.execute_reply":"2025-06-11T11:21:36.127359Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv…","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1f4a04fad36e45d78e4f22da05521b7c"}},"metadata":{}}],"execution_count":5},{"cell_type":"code","source":"from transformers import AutoModelForCausalLM, AutoTokenizer, BitsAndBytesConfig\nfrom peft import PeftModel\nimport torch\n\ntokenizer = AutoTokenizer.from_pretrained(extract_dir)\n\nbnb_config = BitsAndBytesConfig(load_in_4bit=True)\n\nbase_model = AutoModelForCausalLM.from_pretrained(\n    \"mistralai/Mistral-7B-Instruct-v0.3\",\n    device_map=\"auto\",\n    quantization_config=bnb_config,\n    trust_remote_code=True\n)\n\nmodel = PeftModel.from_pretrained(base_model, extract_dir)\nmodel.eval()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-11T11:22:06.569154Z","iopub.execute_input":"2025-06-11T11:22:06.569436Z","iopub.status.idle":"2025-06-11T11:23:28.965235Z","shell.execute_reply.started":"2025-06-11T11:22:06.569414Z","shell.execute_reply":"2025-06-11T11:23:28.964575Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/601 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"21eb033116754228a6b06df57b24cf77"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors.index.json:   0%|          | 0.00/23.9k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"52d1f5e117b648d59322d2e280d5d70b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Fetching 3 files:   0%|          | 0/3 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0cd68f454d944ee0bc0f32dd92ff7a1b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00001-of-00003.safetensors:   0%|          | 0.00/4.95G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0a7787be78474792a0aaaa11b19ad81c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00002-of-00003.safetensors:   0%|          | 0.00/5.00G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"79bc4306c4894be2b5744833a343850f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00003-of-00003.safetensors:   0%|          | 0.00/4.55G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2d9921935c2e490d86e2a78a9bd75bd7"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"65b138f4dca54b1f9e2747848949f11a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"generation_config.json:   0%|          | 0.00/116 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4e3abc90153e4ca78ea66d8a76efb090"}},"metadata":{}},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/peft/config.py:162: UserWarning: Unexpected keyword arguments ['corda_config', 'trainable_token_indices'] for class LoraConfig, these are ignored. This probably means that you're loading a configuration file that was saved using a higher version of the library and additional parameters have been introduced since. It is highly recommended to upgrade the PEFT version before continuing (e.g. by running `pip install -U peft`).\n  warnings.warn(\n","output_type":"stream"},{"execution_count":6,"output_type":"execute_result","data":{"text/plain":"PeftModelForCausalLM(\n  (base_model): LoraModel(\n    (model): MistralForCausalLM(\n      (model): MistralModel(\n        (embed_tokens): Embedding(32768, 4096)\n        (layers): ModuleList(\n          (0-31): 32 x MistralDecoderLayer(\n            (self_attn): MistralAttention(\n              (q_proj): lora.Linear4bit(\n                (base_layer): Linear4bit(in_features=4096, out_features=4096, bias=False)\n                (lora_dropout): ModuleDict(\n                  (default): Dropout(p=0.05, inplace=False)\n                )\n                (lora_A): ModuleDict(\n                  (default): Linear(in_features=4096, out_features=16, bias=False)\n                )\n                (lora_B): ModuleDict(\n                  (default): Linear(in_features=16, out_features=4096, bias=False)\n                )\n                (lora_embedding_A): ParameterDict()\n                (lora_embedding_B): ParameterDict()\n                (lora_magnitude_vector): ModuleDict()\n              )\n              (k_proj): Linear4bit(in_features=4096, out_features=1024, bias=False)\n              (v_proj): lora.Linear4bit(\n                (base_layer): Linear4bit(in_features=4096, out_features=1024, bias=False)\n                (lora_dropout): ModuleDict(\n                  (default): Dropout(p=0.05, inplace=False)\n                )\n                (lora_A): ModuleDict(\n                  (default): Linear(in_features=4096, out_features=16, bias=False)\n                )\n                (lora_B): ModuleDict(\n                  (default): Linear(in_features=16, out_features=1024, bias=False)\n                )\n                (lora_embedding_A): ParameterDict()\n                (lora_embedding_B): ParameterDict()\n                (lora_magnitude_vector): ModuleDict()\n              )\n              (o_proj): Linear4bit(in_features=4096, out_features=4096, bias=False)\n            )\n            (mlp): MistralMLP(\n              (gate_proj): Linear4bit(in_features=4096, out_features=14336, bias=False)\n              (up_proj): Linear4bit(in_features=4096, out_features=14336, bias=False)\n              (down_proj): Linear4bit(in_features=14336, out_features=4096, bias=False)\n              (act_fn): SiLU()\n            )\n            (input_layernorm): MistralRMSNorm((4096,), eps=1e-05)\n            (post_attention_layernorm): MistralRMSNorm((4096,), eps=1e-05)\n          )\n        )\n        (norm): MistralRMSNorm((4096,), eps=1e-05)\n        (rotary_emb): MistralRotaryEmbedding()\n      )\n      (lm_head): Linear(in_features=4096, out_features=32768, bias=False)\n    )\n  )\n)"},"metadata":{}}],"execution_count":6},{"cell_type":"code","source":"def generate_criteria(user_story, max_tokens=512):\n    prompt = f\"\"\"User Story:\n{user_story}\n\nTask: Generate positive and negative acceptance criteria as structured JSON.\"\"\"\n    \n    inputs = tokenizer(prompt, return_tensors=\"pt\").to(\"cuda\")\n\n    output = model.generate(\n        **inputs,\n        max_new_tokens=max_tokens,\n        do_sample=True,\n        top_p=0.9,\n        temperature=0.7,\n        pad_token_id=tokenizer.eos_token_id\n    )\n\n    return tokenizer.decode(output[0], skip_special_tokens=True)\n\nstory = \"As a user, I want to be automatically logged out after 15 minutes of inactivity, so that my session remains secure.\"\nresponse = generate_criteria(story)\nprint(response)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-11T11:26:50.593647Z","iopub.execute_input":"2025-06-11T11:26:50.593992Z","iopub.status.idle":"2025-06-11T11:27:37.124146Z","shell.execute_reply.started":"2025-06-11T11:26:50.593970Z","shell.execute_reply":"2025-06-11T11:27:37.123375Z"}},"outputs":[{"name":"stdout","text":"User Story:\nAs a user, I want to be automatically logged out after 15 minutes of inactivity, so that my session remains secure.\n\nTask: Generate positive and negative acceptance criteria as structured JSON.{\n  \"positive_criteria\": [\n    {\n      \"criterion\": \"The user should be automatically logged out after 15 minutes of inactivity.\",\n      \"role\": \"User\"\n    },\n    {\n      \"criterion\": \"The system should display a warning message when the user is about to be logged out due to inactivity.\",\n      \"role\": \"System\"\n    }\n  ],\n  \"negative_criteria\": [\n    {\n      \"criterion\": \"If the user is actively using the application, they should not be logged out automatically.\",\n      \"role\": \"User\"\n    },\n    {\n      \"criterion\": \"If the system fails to detect user activity for more than 15 minutes, it should not log the user out automatically and display an error message instead.\",\n      \"role\": \"System\"\n    }\n  ]\n}\n### User Story### {\n### Role### {\n### None### }\n### None### }\n### User### {\n### As a user, I want to be automatically logged out after 15 minutes of inactivity, so that my session remains secure.### }\n### Task### {\n### Generate positive and negative acceptance criteria as structured JSON.### }\n### None### {\n### The user should be automatically logged out after 15 minutes of inactivity.### {\n### role: 'User'\n### }\n### The system should display a warning message when the user is about to be logged out due to inactivity.### {\n### role: 'System'\n### }\n### If the user is actively using the application, they should not be logged out automatically.### {\n### role: 'User'\n### }\n### If the system fails to detect user activity for more than 15 minutes, it should not log the user out automatically and display an error message instead.### {\n### role: 'System'\n### }\n### #######\n### #######\n### #######\n### #######\n### #######\n### #######\n### #######\n### #######\n### #######\n### #######\n### #######\n### #######\n### #######\n### #######\n### #######\n### #######\n### #######\n### #######\n### #######\n### #######\n### #######\n### #######\n### #######\n\n","output_type":"stream"}],"execution_count":8},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}